{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Delight on DESC-DC2 simulation  in the context of  Vera C. Rubin Obs (LSST) \n",
    "\n",
    "\n",
    "- author : Sylvie Dagoret-Campagne\n",
    "- affiliation : IJCLab/IN2P3/CNRS\n",
    "- creation date : January 22 2022\n",
    "\n",
    "\n",
    "\n",
    "- run at NERSC with **desc-python** python kernel.\n",
    "\n",
    "\n",
    "Instruction to have a **desc-python** environnement:\n",
    "- https://confluence.slac.stanford.edu/display/LSSTDESC/Getting+Started+with+Anaconda+Python+at+NERSC\n",
    "\n",
    "\n",
    "This environnement is a clone from the **desc-python** environnement where package required in requirements can be addded according the instructions here\n",
    "- https://github.com/LSSTDESC/desc-python/wiki/Add-Packages-to-the-desc-python-environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the parameter file \"tmps/parametersTestRail.cfg\".\n",
    "This contains a description of the bands and data to be used.\n",
    "In this example we will generate mock data for the ugrizy LSST bands,\n",
    "fit each object with our GP using ugi bands only and see how it predicts the rz bands.\n",
    "This is an example for filling in/predicting missing bands in a fully bayesian way\n",
    "with a flexible SED model quickly via our photo-z GP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      6\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import sys,os\n",
    "sys.path.append('../')\n",
    "from delight.io import *\n",
    "from delight.utils import *\n",
    "from delight.photoz_gp import PhotozGP\n",
    "\n",
    "\n",
    "#import logging\n",
    "#import coloredlogs\n",
    "#logger = logging.getLogger(__name__)\n",
    "#coloredlogs.install(level='DEBUG', logger=logger,fmt='%(asctime)s,%(msecs)03d %(programname)s %(name)s[%(process)d] %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "#print(sys.executable)\n",
    "#print(sys.version)\n",
    "#print(sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = \"tmp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration parameters\n",
    "\n",
    "- now parameters are generated in a dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = os.listdir(workdir)\n",
    "list_of_files.remove('data') \n",
    "list_of_files.remove('delight_data') \n",
    "if '.ipynb_checkpoints' in list_of_files:\n",
    "    list_of_files.remove('.ipynb_checkpoints')\n",
    "list_of_configfiles = sorted(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_configfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, we must **fit the band filters with a gaussian mixture**. \n",
    "This is done with this script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_configfiles.remove('parametersTest-Sens.cfg', 'parametersTest-VC1e4_ell1e6.cfg', 'parametersTest-chunks.cfg')\n",
    "print(list_of_configfiles)\n",
    "NCHUNKS = len(list_of_configfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delight.interfaces.rail.processFilters import processFilters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configfilename = list_of_configfiles[9]\n",
    "configfilename = 'parametersTest-chunks.cfg'\n",
    "configfullfilename = os.path.join(workdir,configfilename) \n",
    "processFilters(configfullfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second, we will process the library of SEDs and project them onto the filters,\n",
    "(for the mean fct of the GP) with the following script (which may take a few minutes depending on the settings you set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delight.interfaces.rail.processSEDs import processSEDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configfilename = list_of_configfiles[9]\n",
    "configfilename = 'parametersTest-chunks.cfg'\n",
    "configfullfilename = os.path.join(workdir,configfilename) \n",
    "processSEDs(configfullfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and apply\n",
    "Run the scripts below. There should be a little bit of feedback as it is going through the lines.\n",
    "For up to 1e4 objects it should only take a few minutes max, depending on the settings above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from delight.interfaces.rail.templateFitting import templateFitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_file in range(1,NCHUNKS):\n",
    "    theconfigfile = list_of_configfiles[idx_file]\n",
    "    configfullfilename = os.path.join(workdir,theconfigfile) \n",
    "    templateFitting(configfullfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delight.interfaces.rail.delightLearn import delightLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delightLearn(configfullfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delightApply_paramSpecPlot import delightApply_paramSpecPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_file in range(1,NCHUNKS):\n",
    "    theconfigfile = list_of_configfiles[idx_file]\n",
    "    configfullfilename = os.path.join(workdir,theconfigfile) \n",
    "    delightApply_paramSpecPlot(configfullfilename, plot=False, sensitivity=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First read a bunch of useful stuff from the parameter file.\n",
    "params = parseParamFile(configfullfilename, verbose=False)\n",
    "bandCoefAmplitudes, bandCoefPositions, bandCoefWidths, norms\\\n",
    "    = readBandCoefficients(params)\n",
    "bandNames = params['bandNames']\n",
    "numBands, numCoefs = bandCoefAmplitudes.shape\n",
    "fluxredshifts = np.loadtxt(params['target_catFile'])\n",
    "fluxredshifts_train = np.loadtxt(params['training_catFile'])\n",
    "bandIndices, bandNames, bandColumns, bandVarColumns, redshiftColumn,\\\n",
    "            refBandColumn = readColumnPositions(params, prefix='target_')\n",
    "redshiftDistGrid, redshiftGrid, redshiftGridGP = createGrids(params)\n",
    "dir_seds = params['templates_directory']\n",
    "dir_filters = params['bands_directory']\n",
    "lambdaRef = params['lambdaRef']\n",
    "sed_names = params['templates_names']\n",
    "nt = len(sed_names)\n",
    "f_mod = np.zeros((redshiftGrid.size, nt, len(params['bandNames'])))\n",
    "for t, sed_name in enumerate(sed_names):\n",
    "    f_mod[:, t, :] = np.loadtxt(dir_seds + '/' + sed_name + '_fluxredshiftmod.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the PDF files\n",
    "metrics = np.loadtxt(params['metricsFile'])\n",
    "metricscww = np.loadtxt(params['metricsFileTemp'])\n",
    "# Those of the indices of the true, mean, stdev, map, and map_std redshifts.\n",
    "i_zt, i_zm, i_std_zm, i_zmap, i_std_zmap = 0, 1, 2, 3, 4\n",
    "i_ze = i_zm\n",
    "i_std_ze = i_std_zm\n",
    "\n",
    "pdfs = np.loadtxt(params['redshiftpdfFile'])\n",
    "pdfs_cww = np.loadtxt(params['redshiftpdfFileTemp'])\n",
    "pdfatZ_cww = metricscww[:, 5] / pdfs_cww.max(axis=1)\n",
    "pdfatZ = metrics[:, 5] / pdfs.max(axis=1)\n",
    "nobj = pdfatZ.size\n",
    "#pdfs /= pdfs.max(axis=1)[:, None]\n",
    "#pdfs_cww /= pdfs_cww.max(axis=1)[:, None]\n",
    "pdfs /= np.trapz(pdfs, x=redshiftGrid, axis=1)[:, None]\n",
    "pdfs_cww /= np.trapz(pdfs_cww, x=redshiftGrid, axis=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ncol = 4\n",
    "fig, axs = plt.subplots(5, ncol, figsize=(12, 12), sharex=True, sharey=False)\n",
    "axs = axs.ravel()\n",
    "z = fluxredshifts[:, redshiftColumn]\n",
    "sel = np.random.choice(nobj, axs.size, replace=False)\n",
    "lw = 2\n",
    "for ik in range(axs.size):\n",
    "    k = sel[ik]\n",
    "    print(k, end=\" \")\n",
    "    axs[ik].plot(redshiftGrid, pdfs_cww[k, :],lw=lw, label='Standard template fitting')# c=\"#2ecc71\", \n",
    "    axs[ik].plot(redshiftGrid, pdfs[k, :], lw=lw, label='New method')  #, c=\"#3498db\"\n",
    "    axs[ik].axvline(fluxredshifts[k, redshiftColumn], c=\"k\", lw=1, label='Spec-z')\n",
    "    ymax = np.max(np.concatenate((pdfs[k, :], pdfs_cww[k, :])))\n",
    "    axs[ik].set_ylim([0, ymax*1.2])\n",
    "    axs[ik].set_xlim([0, 3.1])\n",
    "    axs[ik].set_yticks([])\n",
    "    axs[ik].set_xticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4])\n",
    "for i in range(ncol):\n",
    "    axs[-i-1].set_xlabel('Redshift', fontsize=10)\n",
    "axs[0].legend(ncol=3, frameon=False, loc='upper left', bbox_to_anchor=(0.0, 1.4))\n",
    "#fig.tight_layout()\n",
    "#fig.subplots_adjust(wspace=0.1, hspace=0.1, top=0.96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "zmax = 3.1\n",
    "rr = [[0, zmax], [0, zmax]]\n",
    "nbins = 30\n",
    "h = axs[0, 0].hist2d(metricscww[:, i_zt], metricscww[:, i_zm], nbins, cmap='Greys', range=rr)\n",
    "hmin, hmax = np.min(h[0]), np.max(h[0])\n",
    "axs[0, 0].set_title('CWW z mean')\n",
    "axs[0, 1].hist2d(metricscww[:, i_zt], metricscww[:, i_zmap], nbins, cmap='Greys', range=rr, vmax=hmax)\n",
    "axs[0, 1].set_title('CWW z map')\n",
    "axs[1, 0].hist2d(metrics[:, i_zt], metrics[:, i_zm], nbins, cmap='Greys', range=rr, vmax=hmax)\n",
    "axs[1, 0].set_title('GP z mean')\n",
    "axs[1, 1].hist2d(metrics[:, i_zt], metrics[:, i_zmap], nbins, cmap='Greys', range=rr, vmax=hmax)\n",
    "axs[1, 1].set_title('GP z map')\n",
    "axs[0, 0].plot([0, zmax], [0, zmax], c='k')\n",
    "axs[0, 1].plot([0, zmax], [0, zmax], c='k')\n",
    "axs[1, 0].plot([0, zmax], [0, zmax], c='k')\n",
    "axs[1, 1].plot([0, zmax], [0, zmax], c='k')\n",
    "#fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(13, 6))\n",
    "chi2s = ((metrics[:, i_zt] - metrics[:, i_ze])/metrics[:, i_std_ze])**2\n",
    "\n",
    "axs[0].errorbar(metrics[:, i_zt], metrics[:, i_ze], yerr=metrics[:, i_std_ze], fmt='o', markersize=5, capsize=0)\n",
    "axs[1].errorbar(metricscww[:, i_zt], metricscww[:, i_ze], yerr=metricscww[:, i_std_ze], fmt='o', markersize=5, capsize=0)\n",
    "axs[0].plot([0, zmax], [0, zmax], 'k')\n",
    "axs[1].plot([0, zmax], [0, zmax], 'k')\n",
    "axs[0].set_xlim([0, zmax])\n",
    "axs[1].set_xlim([0, zmax])\n",
    "axs[0].set_ylim([0, zmax])\n",
    "axs[1].set_ylim([0, zmax])\n",
    "axs[0].set_title('New method')\n",
    "axs[1].set_title('Standard template fitting')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cmap = \"coolwarm_r\"\n",
    "vmin = 0.0\n",
    "alpha = 0.9\n",
    "s = 5\n",
    "fig, axs = plt.subplots(1, 2, figsize=(13, 5))\n",
    "vs = axs[0].scatter(metricscww[:, i_zt], metricscww[:, i_zmap], \n",
    "                    s=s, c=pdfatZ_cww, cmap=cmap, linewidth=0, vmin=vmin, alpha=alpha)\n",
    "vs = axs[1].scatter(metrics[:, i_zt], metrics[:, i_zmap], \n",
    "                    s=s, c=pdfatZ, cmap=cmap, linewidth=0, vmin=vmin, alpha=alpha)\n",
    "clb = plt.colorbar(vs, ax=axs.ravel().tolist())\n",
    "clb.set_label('Normalized probability at spec-$z$')\n",
    "for i in range(2):\n",
    "    axs[i].plot([0, zmax], [0, zmax], c='k', lw=1, zorder=0, alpha=1)\n",
    "    axs[i].set_ylim([0, zmax])\n",
    "    axs[i].set_xlim([0, zmax])\n",
    "    axs[i].set_xlabel('Spec-$z$')\n",
    "axs[0].set_ylabel('MAP photo-$z$')\n",
    "\n",
    "axs[0].set_title('Standard template fitting')\n",
    "axs[1].set_title('New method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Don't be too harsh with the results of the standard template fitting or the new methods since both have a lot of parameters which can be optimized!\n",
    "\n",
    "If the results above made sense, i.e. the redshifts are reasonnable for both methods on the mock data, then you can start modifying the parameter files and creating catalog files containing actual data! I recommend using less than 20k galaxies for training, and 1000 or 10k galaxies for the delight-apply script at the moment. Future updates will address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Delight-Python",
   "language": "python",
   "name": "delightenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
